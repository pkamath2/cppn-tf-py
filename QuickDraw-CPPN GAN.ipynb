{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from quickdraw import QuickDrawDataGroup\n",
    "from libs import nb_utils, utils, dataset_utils\n",
    "from cppn import CPPN\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'total_drawings = 121380\\nballoons = QuickDrawDataGroup(\"hot air balloon\", max_drawings=total_drawings, refresh_data=True, print_messages =True)\\nfor i in range(total_drawings):\\n    balloon = balloons.get_drawing(i)\\n    balloon.image.save(\"data/balloon/balloon_\"+str(i)+\".gif\")'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Note: Downloads a huge data set.\n",
    "#\n",
    "#\n",
    "'''total_drawings = 121380\n",
    "balloons = QuickDrawDataGroup(\"hot air balloon\", max_drawings=total_drawings, refresh_data=True, print_messages =True)\n",
    "for i in range(total_drawings):\n",
    "    balloon = balloons.get_drawing(i)\n",
    "    balloon.image.save(\"data/balloon/balloon_\"+str(i)+\".gif\")'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/balloon/balloon_0.gif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fee40d37a20>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = sorted([os.path.join('data/balloon/', f) for f in os.listdir('data/balloon/')])\n",
    "print(files[0])\n",
    "plt.imshow(plt.imread(files[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "batch_size=100\n",
    "n_pixels=32\n",
    "n_channels=3\n",
    "input_shape=[None, n_pixels, n_pixels, n_channels]\n",
    "z_dim=32\n",
    "\n",
    "X = tf.placeholder(name='X', shape=input_shape, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used by the discriminator. Creates the latent vector\n",
    "def encoder(x, channels=[50, 50, 50 ,50, 1], filter_sizes=[4, 4, 4, 4, 4], activation=tf.tanh, reuse=None):\n",
    "    h=x\n",
    "    hs=[]\n",
    "    \n",
    "    for layer_i in range(len(channels)):\n",
    "        with tf.variable_scope('layer{}'.format(layer_i+1), reuse=reuse):\n",
    "            h,W = utils.conv2d(x, n_output=channels[layer_i], k_h=filter_sizes[layer_i], k_w=filter_sizes[layer_i], reuse=reuse)\n",
    "            h = activation(h)\n",
    "            hs.append(h)\n",
    "    return h, hs\n",
    "\n",
    "def discriminator(x, channels=[50, 50, 50 ,50, 1], filter_sizes=[4, 4, 4, 4, 4], activation=utils.lrelu, reuse=None):\n",
    "    h=None\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        h, hs = encoder(x, channels, filter_sizes, activation, reuse=reuse)\n",
    "        shape = h.get_shape().as_list()\n",
    "        #h = tf.reshape(h, [-1, shape[1]*shape[2]*shape[3]])\n",
    "        \n",
    "        D,W = utils.linear(x, activation=tf.sigmoid, n_output=1, reuse=reuse)\n",
    "    return D, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/purnima/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "(?, 16, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "D_real, z = discriminator(X)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z_dim=32\n",
    "\n",
    "def generator(z, x_y_dim=n_pixels, channels=[256, 256, 256, n_channels], activation=tf.tanh, reuse=None):\n",
    "    with tf.variable_scope('generator'):\n",
    "        g = CPPN(width=x_y_dim, height=x_y_dim,z=z, channels=n_channels, hidden_neurons=channels[0])\n",
    "        G = g.generate()\n",
    "        shape = G.get_shape().as_list()\n",
    "        G = tf.reshape(G,[1, shape[0], shape[1], shape[2]])\n",
    "    return G\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/purnima/appdir/cppn-tf-py/cppn.py:23: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /home/purnima/appdir/cppn-tf-py/cppn.py:82: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n"
     ]
    }
   ],
   "source": [
    "#Get the first sample\n",
    "G = generator(z, reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'discriminator_1/fc/Sigmoid:0' shape=(1, 1) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_fake, z_fake=discriminator(G, reuse=True)\n",
    "D_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('loss/generator'):\n",
    "    loss_G = tf.reduce_mean(utils.binary_cross_entropy(D_fake, tf.ones_like(D_fake)))\n",
    "with tf.variable_scope('loss/discriminator/real'):\n",
    "    loss_D_real = utils.binary_cross_entropy(D_real, tf.ones_like(D_real))\n",
    "with tf.variable_scope('loss/discriminator/fake'):\n",
    "    loss_D_fake = utils.binary_cross_entropy(D_fake, tf.ones_like(D_fake))\n",
    "with tf.variable_scope('loss/discriminator'):\n",
    "    loss_D = tf.reduce_mean((loss_D_real + loss_D_fake) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.get_default_graph()\n",
    "#nb_utils.show_graph(graph.as_graph_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_d = [v for v in tf.trainable_variables() if v.name.startswith('discriminator')]\n",
    "vars_g = [v for v in tf.trainable_variables() if v.name.startswith('generator')]\n",
    "\n",
    "d_reg = tf.contrib.layers.apply_regularization(tf.contrib.layers.l2_regularizer(1e-6), vars_d)\n",
    "g_reg = tf.contrib.layers.apply_regularization(tf.contrib.layers.l2_regularizer(1e-6), vars_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "\n",
    "lr_g = tf.placeholder(tf.float32, shape=[], name='learning_rate_g')\n",
    "lr_d = tf.placeholder(tf.float32, shape=[], name='learning_rate_d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_g = tf.train.AdamOptimizer(learning_rate=lr_g).minimize(loss_G + g_reg, var_list=vars_g)\n",
    "opt_d = tf.train.AdamOptimizer(learning_rate=lr_d).minimize(loss_D + d_reg, var_list=vars_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/purnima/appdir/cppn-tf-py/libs/dataset_utils.py:49: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /home/purnima/.local/lib/python3.6/site-packages/tensorflow/python/training/input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /home/purnima/.local/lib/python3.6/site-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /home/purnima/.local/lib/python3.6/site-packages/tensorflow/python/training/input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/purnima/.local/lib/python3.6/site-packages/tensorflow/python/training/input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/purnima/.local/lib/python3.6/site-packages/tensorflow/python/training/input.py:202: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/purnima/appdir/cppn-tf-py/libs/dataset_utils.py:52: WholeFileReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.map(tf.read_file)`.\n",
      "WARNING:tensorflow:From /home/purnima/appdir/cppn-tf-py/libs/dataset_utils.py:99: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "n_epochs = 1\n",
    "crop_shape = [n_pixels, n_pixels, 1]\n",
    "crop_factor = 0.8\n",
    "input_shape = [255, 255, 3]\n",
    "\n",
    "batch = dataset_utils.create_input_pipeline(\n",
    "            files=files,\n",
    "            batch_size = batch_size,\n",
    "            n_epochs=n_epochs,\n",
    "            crop_shape = crop_shape,\n",
    "            crop_factor=crop_factor,\n",
    "            shape=input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "equilibrium = 0.693\n",
    "margin = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'shuffle_batch:0' shape=(64, 32, 32, 3) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-80dbe3ea8b66>:15: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "20 real: 0.42591164 / fake: 0.10008892\n",
      "40 real: 0.43337715 / fake: 0.051250957\n",
      "60 real: 0.41779014 / fake: 0.03464887\n",
      "80 real: 0.43295872 / fake: 0.027780743\n",
      "100 real: 0.4297492 / fake: 0.024199553\n",
      "120 real: 0.42400184 / fake: 0.021196146\n",
      "140 real: 0.43332922 / fake: 0.018703053\n",
      "160 real: 0.43043366 / fake: 0.015836885\n",
      "180 real: 0.4295358 / fake: 0.013333665\n",
      "200 real: 0.4196084 / fake: 0.011945622\n",
      "220 real: 0.43321818 / fake: 0.01091087\n",
      "240 real: 0.42321563 / fake: 0.010196278\n",
      "260 real: 0.43015134 / fake: 0.009553323\n",
      "280 real: 0.42357284 / fake: 0.008928161\n",
      "300 real: 0.42402142 / fake: 0.008371247\n",
      "320 real: 0.4393357 / fake: 0.0078046108\n",
      "340 real: 0.4302498 / fake: 0.0073209708\n",
      "360 real: 0.43375748 / fake: 0.006923868\n",
      "380 real: 0.43077824 / fake: 0.0064231963\n",
      "400 real: 0.43367335 / fake: 0.0060581714\n",
      "420 real: 0.4296295 / fake: 0.0058333813\n",
      "440 real: 0.4250679 / fake: 0.005647663\n",
      "460 real: 0.42761415 / fake: 0.005461979\n",
      "480 real: 0.42352405 / fake: 0.0052087423\n",
      "500 real: 0.4291059 / fake: 0.005001395\n",
      "520 real: 0.4265474 / fake: 0.0048291874\n",
      "540 real: 0.44068915 / fake: 0.004689526\n",
      "560 real: 0.4174389 / fake: 0.0045694644\n",
      "580 real: 0.43285245 / fake: 0.0044561224\n",
      "600 real: 0.4404288 / fake: 0.0043370463\n",
      "620 real: 0.43686736 / fake: 0.003978048\n",
      "640 real: 0.43052346 / fake: 0.003891161\n",
      "660 real: 0.43678832 / fake: 0.0038012897\n",
      "680 real: 0.4386896 / fake: 0.0037157342\n",
      "700 real: 0.43730825 / fake: 0.003642569\n",
      "720 real: 0.43087995 / fake: 0.0035696486\n",
      "740 real: 0.41623318 / fake: 0.0034531301\n",
      "760 real: 0.43630055 / fake: 0.003333157\n",
      "780 real: 0.42695963 / fake: 0.0032487775\n",
      "800 real: 0.4196908 / fake: 0.0031349275\n",
      "820 real: 0.44012845 / fake: 0.0028806054\n",
      "840 real: 0.42253718 / fake: 0.0028116256\n",
      "860 real: 0.43575108 / fake: 0.0027314143\n",
      "880 real: 0.44171932 / fake: 0.0026513885\n",
      "900 real: 0.4336455 / fake: 0.0026132008\n",
      "920 real: 0.4364571 / fake: 0.0025786\n",
      "940 real: 0.41628504 / fake: 0.0025454345\n",
      "960 real: 0.4274591 / fake: 0.0025129872\n",
      "980 real: 0.43616188 / fake: 0.0024814971\n",
      "1000 real: 0.44037664 / fake: 0.0024510238\n",
      "1020 real: 0.43039715 / fake: 0.002421567\n",
      "1040 real: 0.4352554 / fake: 0.0023926487\n",
      "1060 real: 0.43917298 / fake: 0.0023634925\n",
      "1080 real: 0.44078457 / fake: 0.0023280638\n",
      "1100 real: 0.43955567 / fake: 0.0022871403\n",
      "1120 real: 0.44404572 / fake: 0.0022573299\n",
      "1140 real: 0.43282175 / fake: 0.0022302086\n",
      "1160 real: 0.43672842 / fake: 0.0022043425\n",
      "1180 real: 0.44235882 / fake: 0.002179373\n",
      "1200 real: 0.43352205 / fake: 0.0021552406\n",
      "1220 real: 0.42589107 / fake: 0.0021318255\n",
      "1240 real: 0.4249814 / fake: 0.0021088289\n",
      "1260 real: 0.42639026 / fake: 0.0020855344\n",
      "1280 real: 0.42402375 / fake: 0.0020628376\n",
      "1300 real: 0.42304933 / fake: 0.0020396037\n"
     ]
    }
   ],
   "source": [
    "ckpt_name = './gan.ckpt'\n",
    "\n",
    "\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "# with tf.device('/CPU'):\n",
    "    config = tf.ConfigProto()\n",
    "#     config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    tf.get_default_graph().finalize()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "#     if os.path.exists(ckpt_name+'.index') or os.path.exists(ckpt_name):\n",
    "#         saver.restore(sess, ckpt_name)\n",
    "#         print('Model restored')\n",
    "        \n",
    "    t_i = 0\n",
    "    batch_i = 0\n",
    "    epoch_i = 0\n",
    "    n_files = len(files)\n",
    "    \n",
    "    if not os.path.exists('imgs'):\n",
    "        os.makedirs('imgs')\n",
    "        \n",
    "    while epoch_i < n_epochs:\n",
    "        batch_i += 1\n",
    "        batch_xs = sess.run(batch) / 255.0\n",
    "        #batch_zs = np.random.uniform(0,0, 1.0, [batch_size, z_dim]).astype(np.float32)\n",
    "        \n",
    "        real_cost, fake_cost = sess.run([loss_D_real, loss_D_fake],\n",
    "                                       feed_dict = {\n",
    "                                            X:batch_xs\n",
    "                                        })\n",
    "        real_cost = np.mean(real_cost)\n",
    "        fake_cost = np.mean(fake_cost)\n",
    "        \n",
    "        if(batch_i%20) == 0:\n",
    "            print(batch_i, 'real:', real_cost, '/ fake:', fake_cost)\n",
    "            \n",
    "        gen_update = True\n",
    "        dis_update = True\n",
    "        \n",
    "        if real_cost > (equilibrium + margin) or fake_cost > (equilibrium + margin):\n",
    "            gen_update = False\n",
    "        \n",
    "        if real_cost < (equilibrium - margin) or fake_cost < (equilibrium-+ margin):\n",
    "            dis_update = False\n",
    "            \n",
    "        if not (gen_update or dis_update):\n",
    "            gen_update = True\n",
    "            dis_update = True\n",
    "        \n",
    "        if dis_update:\n",
    "            sess.run(opt_d, feed_dict={X:batch_xs, lr_d: learning_rate})\n",
    "        \n",
    "        if gen_update:\n",
    "            sess.run(opt_g, feed_dict={lr_g: learning_rate})\n",
    "            \n",
    "        if batch_i % (n_files // batch_size) == 0:\n",
    "            batch_i = 0\n",
    "            epoch_i += 1\n",
    "            print('--------------------------EPOCH: ',epoch_i)\n",
    "            \n",
    "            recon = sess.run(G)\n",
    "            \n",
    "            recon = np.clip(recon, 0, 1)\n",
    "            m1 = utils.montage(recon.reshape([-1]+crop_shape), 'imgs/manifold_%08d.png' % t_i)\n",
    "            \n",
    "            recon = sess.run(G)\n",
    "            m2 = utils.montage(recon.reshape([-1]+crop_shape), 'imgs/reconstructions_%08d.png' % t_i)\n",
    "            \n",
    "            fig, axs = plt.subplots(1,2,figsize(15,10))\n",
    "            axs[0].imshow(m1)\n",
    "            axs[0].imshow(m2)\n",
    "            plt.show()\n",
    "            t_i+=1\n",
    "            \n",
    "            with tf.device('/CPU'):\n",
    "                saver = tf.train.Saver()\n",
    "                save_path = saver.save(sess, './'+ckpt_name, global_step=batch_i, write_meta_graph=False)\n",
    "                print('Model saved in file: %s' % save_path)\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
